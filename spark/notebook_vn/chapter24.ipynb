{"cells":[{"cell_type":"markdown","source":["# What Is MLlib?\nMLlib là một package, được xây dựng và bao gồm trong Spark, cung cấp các giao diện để thu thập và\nlàm sạch dữ liệu, kỹ thuật tính năng và lựa chọn tính năng, đào tạo và điều chỉnh quy mô lớn\ncác mô hình học máy có giám sát và không giám sát, và sử dụng các model đó trong sản xuất.\n## When and why should you use MLlib (versus scikit-learn, TensorFlow, or foo package)\nCó hai trường hợp sử dụng chính mà bạn muốn tận dụng khả năng mở rộng quy mô của Spark. Đầu tiên, bạn muốn\ntận dụng Spark để tiền xử lý và tạo tính năng nhằm giảm lượng thời gian có thể\nđể tạo ra các tập huấn luyện và thử nghiệm từ một lượng lớn dữ liệu. Sau đó, bạn có thể tận dụng\nthư viện học máy đơn để đào tạo trên các tập dữ liệu đã cho đó. Thứ hai, khi dữ liệu đầu vào của bạn\nhoặc kích thước mô hình trở nên quá khó hoặc không thuận tiện để đặt trên một máy, hãy sử dụng Spark để làm\nnâng nặng. Spark làm cho việc học máy phân tán trở nên rất đơn giản.\n\n# High-Level MLlib Concepts\nCó hai trường hợp sử dụng chính mà bạn muốn tận dụng khả năng mở rộng quy mô của Spark. Đầu tiên, bạn muốn\ntận dụng Spark để tiền xử lý và tạo tính năng nhằm giảm lượng thời gian có thể\nđể tạo ra các tập huấn luyện và thử nghiệm từ một lượng lớn dữ liệu. Sau đó, bạn có thể tận dụng\nthư viện học máy đơn để đào tạo trên các tập dữ liệu đã cho đó. Thứ hai, khi dữ liệu đầu vào của bạn\nhoặc kích thước mô hình trở nên quá khó hoặc không thuận tiện để đặt trên một máy, hãy sử dụng Spark để làm\nTrong MLlib có một số kiểu \"cấu trúc\" cơ bản: máy biến áp, máy ước lượng, máy đánh giá,\nvà đường ống. Theo cấu trúc, chúng tôi có nghĩa là bạn sẽ nghĩ về các loại này khi bạn xác định\nđường ống học máy end-to-end. Họ sẽ cung cấp ngôn ngữ chung để xác định những gì\nthuộc phần nào của đường ống. Hình 24-2 minh họa quy trình làm việc tổng thể mà bạn sẽ\ntheo dõi khi phát triển mô hình học máy trong Spark.\n![image.png](attachment:image.png)\n\nTransformers are functions that convert raw data in some way. This might be to create a new\ninteraction variable (from two other variables), normalize a column, or simply change an\nInteger into a Double type to be input into a model. An example of a transformer is one that\nconverts string categorical variables into numerical values that can be used in MLlib.\nTransformers are primarily used in preprocessing and feature engineering. Transformers take a\nDataFrame as input and produce a new DataFrame as output, as illustrated in Figure 24-3.\n![image-2.png](attachment:image-2.png)\n\nCông cụ ước tính là một trong hai loại thứ. Đầu tiên, công cụ ước tính có thể là một loại máy biến áp\nđược khởi tạo với dữ liệu. Ví dụ: để chuẩn hóa dữ liệu số, chúng tôi sẽ cần khởi tạo\nchuyển đổi với một số thông tin về các giá trị hiện tại trong cột mà chúng tôi muốn\nbình thường hóa. Điều này yêu cầu hai lần chuyển qua dữ liệu của chúng tôi — lần chuyển ban đầu tạo ra quá trình khởi tạo\nvà giá trị thứ hai thực sự áp dụng hàm đã tạo trên dữ liệu. Trong Spark's\ndanh pháp, các thuật toán cho phép người dùng đào tạo một mô hình từ dữ liệu cũng được gọi là\nngười lập dự toán.\n\nNgười đánh giá cho phép chúng tôi xem cách một mô hình nhất định hoạt động theo các tiêu chí mà chúng tôi chỉ định như\nđường cong đặc tính hoạt động của máy thu (ROC). Sau khi chúng tôi sử dụng công cụ đánh giá để chọn mô hình tốt nhất\ntừ những mô hình chúng tôi đã thử nghiệm, sau đó chúng tôi có thể sử dụng mô hình đó để đưa ra dự đoán.\nTừ cấp độ cao, chúng tôi có thể chỉ định từng phép biến đổi, ước tính và đánh giá một\nbởi một, nhưng thường dễ dàng hơn khi chỉ định các bước của chúng ta dưới dạng các giai đoạn trong một quy trình. Đường ống này tương tự như\nkhái niệm đường ống của scikit-learning.\n\n## Low-level data types\nNgoài các loại cấu trúc để xây dựng đường ống, cũng có một số dữ liệu cấp thấp hơn\ncác loại bạn có thể cần làm việc trong MLlib (Vector là phổ biến nhất). Bất cứ khi nào chúng ta vượt qua\nmột tập hợp các tính năng thành một mô hình học máy, chúng ta phải thực hiện nó dưới dạng một vectơ bao gồm\nNhân đôi. Vectơ này có thể thưa thớt (trong đó hầu hết các phần tử bằng 0) hoặc dày đặc (trong đó\ncó nhiều giá trị duy nhất). Các vectơ được tạo theo nhiều cách khác nhau. Để tạo một vectơ dày đặc,\nchúng ta có thể chỉ định một mảng tất cả các giá trị. Để tạo một vectơ thưa thớt, chúng tôi có thể chỉ định tổng kích thước\nvà các chỉ số và giá trị của các phần tử khác không. Thưa thớt là định dạng tốt nhất, như bạn có thể có\nđoán, khi phần lớn các giá trị bằng 0 vì đây là một biểu diễn nén hơn. Đây\nlà một ví dụ về cách tạo một Vectơ theo cách thủ công:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d16869f0-29df-4ade-aaf0-33974e3034a0"}}},{"cell_type":"code","source":["# in Python\nfrom pyspark.ml.linalg import Vectors\ndenseVec = Vectors.dense(1.0, 2.0, 3.0)\nsize = 3\nidx = [1, 2] # locations of non-zero elements in vector\nvalues = [2.0, 3.0]\nsparseVec = Vectors.sparse(size, idx, values)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3439c419-510b-4c5f-99f7-13b2c79569a8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##MLlib in Action\nBây giờ chúng tôi đã mô tả một số phần cốt lõi mà bạn có thể mong đợi xem qua, hãy tạo một đường dẫn đơn giản để chứng minh từng thành phần. Chúng tôi sẽ sử dụng một tập dữ liệu tổng hợp nhỏ sẽ giúp minh họa quan điểm của chúng tôi. Hãy cùng đọc dữ liệu và xem mẫu trước khi nói thêm về nó:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"270d8265-0e31-4375-8ebb-cb08bbc20ef2"}}},{"cell_type":"code","source":["from pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nsc = SparkContext('local')\nspark = SparkSession(sc)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b85a6a0-9512-4ae2-9643-22ee40854add"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.read.json(\"../data/simple-ml\")\ndf.orderBy(\"value2\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07248590-84af-4de5-9733-e627b78dc979"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Feature Engineering with Transformers\nKhi chúng tôi sử dụng MLlib, tất cả các đầu vào cho các thuật toán học máy (với một số ngoại lệ\nđược thảo luận trong các chương sau) trong Spark phải bao gồm loại Double (cho nhãn) và\nVector [Double] (đối với các tính năng). Tập dữ liệu hiện tại không đáp ứng yêu cầu đó và do đó\nchúng ta cần chuyển đổi nó sang định dạng thích hợp.\n\nĐể đạt được điều này trong ví dụ của chúng tôi, chúng tôi sẽ chỉ định một RFormula. Đây là một khai báo\nngôn ngữ để chỉ định các chuyển đổi học máy và rất dễ sử dụng khi bạn\nhiểu cú pháp. RFormula hỗ trợ một tập con giới hạn của các toán tử R mà trong thực tế\nhoạt động khá tốt đối với các mô hình và thao tác đơn giản (chúng tôi chứng minh cách tiếp cận thủ công để\nvấn đề này trong Chương 25)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"80d554ca-6060-471a-acbc-2ceeb83e850d"}}},{"cell_type":"code","source":["from pyspark.ml.feature import RFormula\nsupervised = RFormula(formula=\"lab ~ . + color:value1 + color:value2\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a86ad99e-1948-4a28-86d4-54fde3b5c874"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Tại thời điểm này, chúng tôi đã chỉ định rõ ràng cách chúng tôi muốn thay đổi dữ liệu của mình thành những gì chúng tôi\nsẽ đào tạo mô hình của chúng tôi về. Bước tiếp theo là lắp biến áp RFormula với dữ liệu để cho nó\nkhám phá các giá trị có thể có của mỗi cột. Không phải tất cả các máy biến áp đều có yêu cầu này nhưng\nbởi vì RFormula sẽ tự động xử lý các biến phân loại cho chúng ta, nó cần xác định\ncột nào được phân loại và cột nào không, cũng như giá trị khác biệt của\ncột phân loại là. Vì lý do này, chúng ta phải gọi là phương pháp phù hợp. Một khi chúng tôi gọi là phù hợp, nó\ntrả về phiên bản \"được đào tạo\" của máy biến áp mà chúng tôi có thể sử dụng để thực sự biến đổi dữ liệu của mình."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed544ff8-1553-41e5-ace2-e987a8537279"}}},{"cell_type":"code","source":["fittedRF = supervised.fit(df)\npreparedDF = fittedRF.transform(df)\npreparedDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d4e9d7d-8231-41b9-a6c2-5fefa9aaa2b5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Trong đầu ra, chúng ta có thể thấy kết quả của quá trình chuyển đổi của mình — một cột được gọi là các tính năng có\ndữ liệu thô trước đây. Những gì đang xảy ra đằng sau hậu trường thực sự khá đơn giản. RFormula\nkiểm tra dữ liệu của chúng tôi trong khi gọi phù hợp và xuất ra một đối tượng sẽ biến đổi dữ liệu của chúng tôi theo\ncông thức được chỉ định, được gọi là RFormulaModel. Máy biến áp \"được đào tạo\" này luôn\ncó từ Model trong chữ ký loại. Khi chúng tôi sử dụng máy biến áp này, Spark sẽ tự động\nchuyển đổi biến phân loại của chúng tôi thành Double để chúng tôi có thể nhập nó vào một (chưa được chỉ định)\nmô hình học máy. Đặc biệt, nó chỉ định một giá trị số cho mỗi màu có thể\ndanh mục, tạo các tính năng bổ sung cho các biến tương tác giữa các màu và\nvalue1 / value2 và đặt tất cả chúng vào một vectơ duy nhất. Sau đó, chúng tôi gọi biến đổi trên đối tượng đó trong\nđể chuyển đổi dữ liệu đầu vào của chúng tôi thành dữ liệu đầu ra mong đợi.\n\nCho đến nay, bạn (trước) đã xử lý dữ liệu và thêm một số tính năng trên đường đi. Bây giờ là lúc để\nthực sự đào tạo một mô hình (hoặc một tập hợp các mô hình) trên tập dữ liệu này. Để làm được điều này, trước tiên bạn cần\nchuẩn bị một bộ thử nghiệm để đánh giá.\n\nBây giờ chúng ta hãy tạo một bộ thử nghiệm đơn giản dựa trên sự phân tách ngẫu nhiên của dữ liệu (chúng tôi sẽ sử dụng bộ thử nghiệm này\ntrong suốt phần còn lại của chương):"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acabf8e6-598d-46a7-95ce-91a2e3e9aa4e"}}},{"cell_type":"code","source":["train, test = preparedDF.randomSplit([0.7, 0.3])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97b561f5-7c1f-414a-a9c7-892d244bdf75"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["print(lr.explainParams())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7952640b-0201-4b31-b44e-c2b4107bbdc9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["fittedLR = lr.fit(train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1649cce7-5790-4f34-b7a5-11b1c0d2dc27"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Mã này sẽ bắt đầu một công việc Spark để đào tạo mô hình. Trái ngược với những biến đổi mà bạn\ntrong suốt cuốn sách, việc lắp mô hình máy học được mong đợi và thực hiện\nngay.\n\nSau khi hoàn thành, bạn có thể sử dụng mô hình để đưa ra dự đoán. Về mặt logic, điều này có nghĩa là chuyển đổi\ncác tính năng vào nhãn. Chúng tôi đưa ra dự đoán với phương pháp biến đổi. Ví dụ, chúng ta có thể\nchuyển đổi tập dữ liệu đào tạo của chúng tôi để xem mô hình của chúng tôi được gán nhãn nào cho dữ liệu đào tạo và cách\nso với kết quả đầu ra thực sự. Đây, một lần nữa, chỉ là một DataFrame khác mà chúng ta có thể thao tác.\nHãy thực hiện dự đoán đó với đoạn mã sau:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"38e10666-3d72-47d0-acc5-e314759d3711"}}},{"cell_type":"code","source":["fittedLR.transform(train).select(\"label\", \"prediction\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc612464-8f94-4971-bbe4-5b715f102847"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## ĐÁNH GIÁ VỀ HYPERPARAMETERS\nMặc dù trước đây chúng ta đã đề cập đến chúng, nhưng chúng ta hãy định nghĩa chính thức hơn về siêu tham số.\nSiêu tham số là các tham số cấu hình ảnh hưởng đến quá trình đào tạo, chẳng hạn như mô hình\nkiến trúc và chính quy hóa. Chúng được thiết lập trước khi bắt đầu đào tạo. Ví dụ, hậu cần\nhồi quy có một siêu tham số xác định mức độ chính xác hóa\nđược thực hiện trên dữ liệu của chúng tôi thông qua giai đoạn đào tạo (chính quy hóa là một kỹ thuật thúc đẩy\nmô hình chống lại dữ liệu trang bị quá mức). Bạn sẽ thấy trong một vài trang tiếp theo mà chúng tôi có thể thiết lập\nđường ống để thử các giá trị siêu tham số khác nhau (ví dụ: các giá trị chính quy khác nhau) theo thứ tự\nđể so sánh các biến thể khác nhau của cùng một mô hình với nhau.\n\n## Pipelining Workflow của chúng tôi\nNhư bạn có thể nhận thấy, nếu bạn đang thực hiện nhiều phép biến đổi, hãy viết tất cả các bước và\ntheo dõi DataFrames cuối cùng khá tẻ nhạt. Đó là lý do tại sao Spark bao gồm\nKhái niệm đường ống. Đường ống cho phép bạn thiết lập luồng dữ liệu của các chuyển đổi có liên quan\nkết thúc bằng một công cụ ước tính được tự động điều chỉnh theo thông số kỹ thuật của bạn, dẫn đến\ntrong một mô hình đã được điều chỉnh sẵn sàng để sử dụng. Hình 24-4 minh họa quá trình này.\n! [image.png] (file đính kèm: image.png)\n\nLưu ý rằng điều cần thiết là các trường hợp máy biến áp hoặc mô hình không được sử dụng lại trên các\nđường ống dẫn. Luôn tạo một phiên bản mới của một mô hình trước khi tạo một đường dẫn khác.\n\nĐể đảm bảo rằng chúng tôi không trang bị quá nhiều, chúng tôi sẽ tạo một bộ thử nghiệm lưu giữ và điều chỉnh\nsiêu tham số dựa trên bộ xác thực (lưu ý rằng chúng tôi tạo bộ xác thực này dựa trên\ntập dữ liệu gốc, không phảiDF đã chuẩn bị được sử dụng trong các trang trước):"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6d4e019-6ca4-40cc-89c2-e563775b5942"}}},{"cell_type":"code","source":["train, test = df.randomSplit([0.7, 0.3])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06abfea9-76c7-4876-85ab-a56707c177bd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Bây giờ bạn đã có một tập hợp khoản lưu giữ, hãy tạo các giai đoạn cơ bản trong quy trình của chúng tôi. Một giai đoạn đơn giản\nđại diện cho một máy biến áp hoặc một máy ước lượng. Trong trường hợp của chúng tôi, chúng tôi sẽ có hai công cụ ước tính. RFomula\ntrước tiên sẽ phân tích dữ liệu của chúng tôi để hiểu các loại tính năng đầu vào và sau đó chuyển đổi chúng thành\ntạo các tính năng mới. Sau đó, đối tượng LogisticRegression là thuật toán mà chúng ta sẽ\nđào tạo để sản xuất một mô hình:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d43057e-2a37-4895-94c4-e05a44ec7bd0"}}},{"cell_type":"code","source":["rForm = RFormula()\nlr = LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7252b25b-2010-4299-995f-81dd395cf5b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Chúng tôi sẽ đặt các giá trị tiềm năng cho RFormula trong phần tiếp theo. Bây giờ thay vì thủ công\nbằng cách sử dụng các phép biến đổi và sau đó điều chỉnh mô hình của mình, chúng tôi chỉ làm cho chúng theo từng giai đoạn trong tổng thể\nđường ống dẫn, như trong đoạn mã sau:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7bb5773f-86e5-4c31-96b9-9720631b69f2"}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nstages = [rForm, lr]\npipeline = Pipeline().setStages(stages)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aeaabf96-3aaa-4666-a768-cd3da6637ba8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Đào tạo và Đánh giá\nBây giờ bạn đã sắp xếp đường ống hợp lý, bước tiếp theo là đào tạo. Trong trường hợp của chúng tôi, chúng tôi sẽ không đào tạo\nchỉ một mô hình (như chúng tôi đã làm trước đây); chúng tôi sẽ đào tạo một số biến thể của mô hình bằng cách\nxác định các tổ hợp siêu thông số khác nhau mà chúng tôi muốn Spark kiểm tra. Chúng tôi sẽ\nsau đó chọn mô hình tốt nhất bằng cách sử dụng Người đánh giá so sánh các dự đoán của họ về xác thực của chúng tôi\ndữ liệu. Chúng tôi có thể kiểm tra các siêu thông số khác nhau trong toàn bộ đường ống, ngay cả trong RFormula mà chúng tôi\nsử dụng để thao tác với dữ liệu thô. Đoạn mã này cho thấy cách chúng tôi thực hiện điều đó:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b29c09d-7051-47d8-a3e4-5428342dea9b"}}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\nparams = ParamGridBuilder()\\\n.addGrid(rForm.formula, [\n\"lab ~ . + color:value1\",\n\"lab ~ . + color:value1 + color:value2\"])\\\n.addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n.addGrid(lr.regParam, [0.1, 2.0])\\\n.build()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87c879f6-ca47-4ac3-b40d-444d144b21d9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["In our current paramter grid, there are three hyperparameters that will diverge from the defaults:\n1. Two different versions of the RFormula\n2. Three different options for the ElasticNet parameter\n3. Two different options for the regularization parameter\n\nThis gives us a total of 12 different combinations of these parameters, which means we will be\ntraining 12 different versions of logistic regression.\n\nNow that the grid is built, it’s time to specify our evaluation process. The evaluator allows us to\nautomatically and objectively compare multiple models to the same evaluation metric. There are\nevaluators for classification and regression, covered in later chapters, but in this case we will use\nthe BinaryClassificationEvaluator, which has a number of potential evaluation metrics, as\nwe’ll discuss in Chapter 26. In this case we will use areaUnderROC, which is the total area under\nthe receiver operating characteristic, a common measure of classification performance:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d9befd0-f034-40bd-a5e5-a20d152fa04b"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"chapter24","dashboards":[],"language":"python","widgets":{},"notebookOrigID":1565957064536378}},"nbformat":4,"nbformat_minor":0}
